# MarkItDown.GUI

シンプルなドラッグ&ドロップ操作で、様々なファイル形式をMarkdown形式に変換するWindowsアプリケーションです。WebページのスクレイピングによるJSON出力にも対応しています。

## 特徴

- **簡単操作**: ファイルやフォルダをウィンドウにドロップするだけで自動変換
- **多様なファイル形式に対応**: Office文書、PDF、画像、音声、テキスト、アーカイブなど幅広く対応
- **Webスクレイピング**: URLを入力するだけでWebページの内容をJSON形式で抽出・保存
  - Reddit: JSON API による高速取得
  - その他のサイト: Playwright + Ollamaガイド型で動的コンテンツ（ページネーション・無限スクロール等）にも対応
- **自動環境構築**: Python環境、FFmpeg、Ollamaを初回起動時に自動でダウンロード・セットアップ
- **OSの環境を汚さないポータブル設計**: Python・FFmpeg・Ollama・LLMモデルなど全ての依存コンポーネントをアプリ内の `lib/` フォルダに格納。システムのPATH・レジストリ・既存のPython環境には一切影響しません。アンインストール時もフォルダ削除だけで完全にクリーンアップできます
- **Ollama連携 (gemma3:4b)**: ローカルLLM を使用した画像説明の自動生成、Markdown整形、スクレイピング戦略分析を統合
- **LLMによる自動整形**: 全ファイル形式の変換結果をOllamaで自動的に整形（元データを損失しない軽量プロンプト）
- **並列処理**: 最大3ファイルの同時変換で高速処理
- **重複処理の回避**: 同じファイルの再処理をキャッシュでスキップ
- **パッケージ自動更新**: 起動時にPythonパッケージ（markitdown、openai、playwright）の最新バージョンを自動確認・更新
- **自動アップデート**: アプリ起動時に最新版を自動チェック・適用
- **モダンなUI**: Avalonia UIを使用した軽量で使いやすいインターフェース（処理中オーバーレイによる進捗表示付き）

## ダウンロード

最新版は以下のGitHub Releasesページからダウンロードできます。

**[📥 ダウンロードページ（GitHub Releases）](https://github.com/1llum1n4t1s/MarkItDown.GUI/releases)**

`Setup.exe` をダウンロードして実行してください。

## サポートしているファイル形式

### テキスト・文書ファイル
- `.txt`, `.html`, `.htm`, `.csv`, `.xml`

### Office文書
- `.docx`, `.doc`, `.xlsx`, `.xls`, `.pptx`, `.ppt`

### PDFファイル
- `.pdf`

### 画像ファイル
- `.jpg`, `.jpeg`, `.png`, `.gif`, `.bmp`, `.tiff`, `.tif`, `.webp`

### 音声ファイル
- `.mp3`, `.wav`, `.flac`, `.aac`, `.ogg`

### アーカイブファイル
- `.zip`, `.rar`, `.7z`, `.tar`, `.gz`

> **注意**: `.md` と `.json` はアプリの出力形式と同一のため、フォルダドロップ時の変換対象から自動的に除外されます。

## 使い方

### ファイル変換

1. アプリケーションを起動します（初回はPython環境・FFmpeg・Ollamaの自動セットアップが行われます）
2. 変換したいファイルまたはフォルダをウィンドウにドラッグ&ドロップします
3. 自動的に変換が開始され、元のファイルと同じ場所にMarkdownファイル（`.md`）が生成されます

変換されたファイルは `ファイル名_YYYYMMDDHHmmss.md` という形式で保存されます。

フォルダをドロップした場合は、フォルダ内のサポート対象ファイルを再帰的に検索し、最大3ファイルずつ並列で変換します。

### Webスクレイピング

1. ウィンドウ上部のURL入力欄にWebページのURLを入力します
2. 「🌐 抽出」ボタンをクリックします
3. スクレイピングが実行され、デスクトップにJSONファイルが保存されます

処理中はオーバーレイに現在の進行状況（依存パッケージ確認 → Playwrightスクレイピング → Ollama JSON整形）がリアルタイムで表示されます。

#### 対応サイト

| サイト種別 | 取得方法 | 特徴 |
|---|---|---|
| Reddit | JSON API | 投稿・コメントを高速取得 |
| その他 | Playwright + Ollama | ヘッドレスブラウザで動的コンテンツに対応 |

#### Ollamaガイド型スクレイピング

Playwright（ヘッドレスブラウザ）とOllama（ローカルLLM）を組み合わせて、以下の動的コンテンツに対応します：

- ページネーション（「次へ」ボタン）
- 「もっと見る」ボタン
- 無限スクロール
- Cookie同意バナーの自動処理

OllamaのOpenAI互換チャットAPI（`/v1/chat/completions`）を使用して、ページの構造を分析し最適なスクレイピング戦略を決定します。マルチモーダルモデル（gemma3）を使用している場合、ページのスクリーンショットも分析に活用されます。

## Ollama連携機能（自動セットアップ）

Ollamaと **gemma3:4b**（Google製マルチモーダルモデル）を使用して、以下のLLM連携機能を提供します。

- **画像説明の自動生成**: 画像ファイルをドロップすると、MarkItDownのネイティブLLM統合により画像の説明文を日本語で自動生成します
- **Markdown整形**: 全ファイル形式の変換結果を、Ollamaで自動的にきれいなMarkdown形式に整形します（元データを損失しない軽量プロンプト）
- **スクレイピング戦略分析**: Webスクレイピング時にページ構造（DOM統計、HTMLサンプル、スクリーンショット）を分析し、最適なCSSセレクタと抽出戦略を動的に決定します
- **スクレイピングJSON整形**: Webスクレイピング結果のJSONを構造化・整形します（大きなJSONはチャンク分割で処理）

> **使用モデル**: `gemma3:4b` はアプリ内部で固定されており、設定変更は不要です。テキストと画像の両方を理解できるマルチモーダルモデルで、約3.3GBのディスク容量を使用します。

### 自動セットアップ

**初回起動時に自動的に実行されます：**

1. **Ollamaの自動ダウンロード**
   - アプリケーション起動時、Ollamaが組み込まれていない場合は自動的にダウンロードされます
   - GitHubから最新版のOllama for Windowsを取得します
   - ダウンロード先: `lib/ollama/` フォルダ

2. **Ollamaサーバーの自動起動**
   - ダウンロード完了後、バックグラウンドでOllamaサーバーを起動します
   - `http://localhost:11434` で待機します

3. **gemma3:4bモデルの自動ダウンロード**
   - `gemma3:4b` モデルが存在しない場合、自動的にダウンロードを開始します
   - 初回は約3.3GBのダウンロードが発生します
   - ダウンロード中もログに進捗が表示されます

4. **完了**
   - ログに「Ollamaが利用可能です」と表示されれば準備完了です
   - 画像ファイルをドロップすると、自動的に説明が生成されます
   - ファイルをドロップすると、変換後にLLMでMarkdownが整形されます

### 設定のカスタマイズ

設定ファイル `appsettings.xml` で以下をカスタマイズできます：

```xml
<AppSettings>
  <OllamaUrl>http://localhost:11434</OllamaUrl>
  <OllamaGpuDevice>0</OllamaGpuDevice>
</AppSettings>
```

| 設定項目 | 説明 | デフォルト値 |
|---|---|---|
| `OllamaUrl` | OllamaサーバーのエンドポイントURL | `http://localhost:11434` |
| `OllamaGpuDevice` | 使用するGPUデバイスID | `0`（自動検出） |

#### GPU設定（OllamaGpuDevice）

使用するGPUを指定できます：

- **未設定または`0`** (デフォルト): Ollamaが自動でGPUを検出して使用（推奨）
- **`1`**: GPU 1のみを使用
- **`0,1`**: GPU 0と1の両方を使用
- **`-1`**: CPUのみ使用（GPUを使用しない）

`CUDA_VISIBLE_DEVICES`を設定すると環境によってはGPUが検出されない場合があるため、デフォルトでは未設定（自動検出）にしています。複数GPUで特定のGPUを使いたい場合のみ設定してください。

**GPU IDの確認方法:**
コマンドプロンプトで `nvidia-smi -L` を実行すると、利用可能なGPUのリストが表示されます。

### 注意事項

- **初回起動時の所要時間**: Ollamaとgemma3:4bモデルのダウンロードに10～30分程度かかる場合があります（ネットワーク速度に依存）
- **ディスク容量**: Ollama本体（約200MB）+ gemma3:4bモデル（約3.3GB）が必要です
- **メモリ要件**: モデル実行時に8GB以上のRAMを推奨します
- Ollamaのダウンロードに失敗した場合でも、画像ファイルの基本情報（ファイル名、サイズなど）は出力されます
- 画像説明の生成には数秒～数十秒かかる場合があります（初回のモデルロード時はさらに時間がかかります）

## 自動環境構築

初回起動時に以下のコンポーネントが自動的にダウンロード・セットアップされます。

| コンポーネント | 用途 | 配置先 |
|---|---|---|
| 埋め込みPython 3.10+ | MarkItDownライブラリの実行環境 | `lib/python/python-embed/` |
| FFmpeg | 音声ファイルの処理 | `lib/ffmpeg/` |
| Ollama | LLM推論エンジン（gemma3:4b） | `lib/ollama/` |
| markitdown（最新版） | ファイル変換ライブラリ（pip自動インストール・更新） | Python site-packages |
| openai | OllamaのOpenAI互換API利用（pip自動インストール・更新） | Python site-packages |
| playwright | Webスクレイピング用ブラウザ自動化（pip自動インストール・更新） | Python site-packages |

### OSの環境を汚さないポータブル設計

全ての依存コンポーネントはアプリケーションフォルダ内の `lib/` 配下に自己完結して格納されます。

- **Python**: 公式の埋め込み版（Windows Embeddable Package）を使用。システムにインストール済みのPython環境には一切干渉しません
- **Pythonパッケージ**: markitdown、openai、playwright等は埋め込みPython専用の site-packages にインストールされます
- **FFmpeg**: `lib/ffmpeg/` に格納。システムのPATHやレジストリは変更しません
- **Ollama & LLMモデル**: `lib/ollama/` に格納。システムにインストールされたOllamaとは独立して動作します

アンインストール時はアプリケーションフォルダを削除するだけで、OS上に痕跡を残しません。

起動時にこれらのPythonパッケージの最新バージョンが自動的に確認・更新されます。

> **技術的補足**: markitdown 0.1.x は `onnxruntime<=1.20.1` を要求しますが、Python 3.14 では onnxruntime 1.24.1+ しか利用できないため、依存パッケージを先にインストールした後、markitdown本体を `--no-deps` オプションでインストールしています。実際にはonnxruntime 1.24.1でも正常に動作します。

## 動作環境

- Windows 11 (ビルド 26200以降)
- .NET 10.0 Runtime（インストーラーに含まれています）

## 技術仕様

- **フレームワーク**: Avalonia UI 11.3 / .NET 10.0
- **言語**: C# 14 / Python 3.10+
- **アーキテクチャ**: MVVM (Model-View-ViewModel)
- **ファイル変換**: Microsoft MarkItDown（Python）
- **LLMモデル**: gemma3:4b（Google製マルチモーダルモデル、アプリ内部固定）
- **Webスクレイピング**: Playwright（ヘッドレスブラウザ）+ Ollama（構造分析・スクリーンショット解析）
- **LLM連携**: Ollama OpenAI互換API (`/v1/chat/completions`)
- **自動更新**: Velopack
- **ログ**: ZLogger（ローリングファイル出力）

## ライセンス

このプロジェクトはMITライセンスの下で公開されています。詳細は [LICENSE](LICENSE) ファイルをご覧ください。
